# <center>NLP: Множественная классификация текстов отзывов.</center>
---

## Описание проекта.

### Задача
Множественная классификация текстов для определения всех классов, к которым можно отнести каждый экземпляр.

Множественная классификация отличается от многоклассовой тем, что экземпляр данных может одновременно относиться сразу к нескольким классам.

В данных представлены ответы на опрос, состоящий из части с выбором ответа из списка и расширенного комментария с произвольным текстом. Необходимо для каждого ответа из 50 различных меток классов выбрать все затронутые.

### Метрика (default)
Метрикой в данной задаче является Accuracy, которая в множественной классификации считается через полное совпадение списка выбранных классов для каждого экземпляра.
Acuracy = (Количество полных совпадений списка выбранных классов с таргетом) / (общая сумма экземпляров).
```
import numpy as np
accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))
>>> 0.5
```

### Данные
- `train.csv.zip` - обучающая выборка;

|Название столбца|Описание столбца|
|:-|:-|
|index|Id объекта|
|assessment|Числовая оценка заказа, проставленная пользователем|
|tags|Категорийные тэги отзыва|
|text|Текстовый коментарий|
|trend_id_res$X$|Код класса: $X ∈ [1, 50]$|

- `test.csv.zip` - тестовая выборка: аналогична обучающей, но без разметки классов;
- `trend_description` - описание классов;
- `baseline.ipynb` - бейзлайн (`TfIdf` и логит. регрессия);
- `sample_submission.csv.zip` - пример посылки;
- `NLP User experience multilabel classification.docx` - ТЗ.



### Решения
- _Решение 1_.<br>
Несмотря на присутствие в датасете большого количества объектов со всеми отрицательными классами, обучение на всём датасете может увеличить понимание моделью признаков.
  - Результат: `accuracy` - `0.61`.
  - Ссылка на решение (ноутбук `Notebooks/Ya_NLP_Mutlilabel_Samokat_catboost.ipynb`)
  - Модель:
    - `CatBoostClassifier`.
  - Данные:
    - создание эмбеддингов текста с помощью легковесной `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
    - кодировка тэгов как бинарных признаков;
    - оценки оставим без изменений.
	
- _Решение 2_.<br>
Очистка датасета от объектов со всеми отрицательными классами поможет модели в классификации, т.к., исходя из описания классов, хотя бы один из них должен быть положительным, следовательно датасет недоразмечен.<br>
  - Результат:<br>
Решение не сработало. Нейросеть требует больше времени на доработку и эксперименты с включением тэгов/оценок в текст и пр.<br>
  - Ссылка на решение (ноутбук`Notebooks/Tests/Ya_NLP_Mutlilabel_Samokat_MixedInputNN.ipynb`).
  - Модель:<br>
    Для более глубокого понимания датасета моделью и из-за сравнительно небольшого кол-ва размеченных классов, обучим на очищенных данных нейросеть со смешаным входом.
  - Данные:
    - для текстовых данных - большая русскоязычная модель `ai-forever/ruRoberta-large`;
    - тэги закодированы как бинарные признаки;
    - оценки без изменений.

- _Решение 3_. <br>
Т.к. точно размеченных данных относительно немного, может сработать самообучение модели с псевдоразметкой: обучение классификатора на размеченных данных и последующее итеративное включение предсказаний с заданной точностью в обучающую выборку с переобучением модели.<br>
  - Результат:<br>
Решение не сработало. Хорошим экспериментом была бы проверка самообучения большой языковой модели типа `ruGPT` или подобных, на работу с которыми требуется больше времени и ресурсов.<br>
  - Ссылка на решение (ноутбук `Notebooks/Tests/Ya_NLP_Mutlilabel_Samokat_catboost_self_training.ipynb`).
  - Модель:<br>
    `CatBoostClassifier`.
  - Данные:
    - эмбеддинги текста с помощью более легковесной `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
    - тэги как бинарные признаки;
    - оценки без изменений.
	
- __Примечание__:
эксперименты с классификацией языковами моделями (`ruRoberta-large`) только текста без оценок и тэгов к успеху не привели - `accuracy` не превысила `~0.53`.